{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f329ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DSE511. Project 3. Part3. Modeling. Code for Linear Regression modeling.Albina Jetybayeva\n",
    "def linreg_Albina(housing, housing_labels, housing_t, housing_labels_t):\n",
    "    #Import libraries\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.metrics import r2_score\n",
    "    from matplotlib.pyplot import figure\n",
    "    \n",
    "    #%%time\n",
    "    #Model Linear Regression\n",
    "    print(\"Linear Regression\")\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(housing, housing_labels)\n",
    "    #%%time\n",
    "    housing_pred = lin_reg.predict(housing_t)\n",
    "    \n",
    "    #Evaluate model\n",
    "    \n",
    "    lin_mse = mean_squared_error(housing_labels_t, housing_pred)\n",
    "    lin_rmse = np.sqrt(lin_mse)\n",
    "    print(\"RMSE for Linear Regression: \", lin_rmse)\n",
    "    \n",
    "    lin_mae = mean_absolute_error(housing_labels_t, housing_pred)\n",
    "    print(\"MAE for Linear Regression: \", lin_mae)\n",
    "    \n",
    "    lin_scores = cross_val_score(lin_reg, housing, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "    lin_rmse_scores_mean=lin_rmse_scores.mean()\n",
    "    print(\"Cross validation mean score for Linear Regression: \", lin_rmse_scores_mean)\n",
    "    lr_confidence = lin_reg.score(housing_t, housing_labels_t)\n",
    "    print(\"Confidence score for Linear Regression: \", lr_confidence)\n",
    "    #Visualize the predicted and actual prices\n",
    "    \n",
    "    housing_pred_lr = lin_reg.predict(housing_t)\n",
    "    plt.figure()\n",
    "    plt.errorbar(housing_labels_t, housing_pred_lr, fmt='o', alpha=0.2)\n",
    "    plt.title('Linear regression, R2=%.2f' % r2_score(housing_labels_t, housing_pred_lr))\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    importance = lin_reg.coef_\n",
    "    # summarize feature importance\n",
    "    for i,v in enumerate(importance):\n",
    "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "        # plot feature importance\n",
    "    plt.bar([x for x in range(len(importance))], importance)\n",
    "    plt.show()\n",
    "    #To get the exact names of features create the table\n",
    "    coef_table = pd.DataFrame(list(housing.columns)).copy()\n",
    "    coef_table.columns = ['Features']\n",
    "    coef_table.insert(len(coef_table.columns),\"Coefs\",lin_reg.coef_.transpose())\n",
    "    print(coef_table)\n",
    "    coef_table_sorted=coef_table.sort_values(by='Coefs')\n",
    "    \n",
    "    figure()\n",
    "    # Creating a horizontal graph with the values from the pandas Series.\n",
    "    coef_table_sorted.plot.barh(x='Features', y='Coefs', color=\"green\")\n",
    "    plt.title(\"Feature importance for Linear Regression\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.show()\n",
    "    \n",
    "    #To evaluate the performance of the Linear Regression model from the different perspective \n",
    "    #the only important features observed above will be considered in the next part. \n",
    "    #So that \"total_rooms\", \"total_bedrooms\", \"ocean_proximity\", \"population_per_household\" will be dropped.\n",
    "    \n",
    "    #Linear Regression dropped features\n",
    "    print(\"Linear Regression with dropped features\")\n",
    "    housing_new = housing.drop([\"total_rooms\", \"total_bedrooms\", \"ocean_proximity\", \"population_per_household\"], axis=1) # drop labels for training set\n",
    "    housing_t_new = housing_t.drop([\"total_rooms\", \"total_bedrooms\", \"ocean_proximity\", \"population_per_household\"], axis=1) # drop labels for training set\n",
    "    #%%time\n",
    "    lin_reg1 = LinearRegression()\n",
    "    lin_reg1.fit(housing_new, housing_labels)\n",
    "    #%%time\n",
    "    housing_pred1 = lin_reg1.predict(housing_t_new)\n",
    "    #Evaluate Model\n",
    "    lin_mse1 = mean_squared_error(housing_labels_t, housing_pred1)\n",
    "    lin_rmse1 = np.sqrt(lin_mse1)\n",
    "    print(\"RMSE for Linear Regression with dropped features: \", lin_rmse1)\n",
    "    lin_mae1 = mean_absolute_error(housing_labels_t, housing_pred1)\n",
    "    print(\"MAE for Linear Regression with dropped features: \",lin_mae1)\n",
    "    lin_scores1 = cross_val_score(lin_reg1, housing_new, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    lin_rmse_scores1 = np.sqrt(-lin_scores1)\n",
    "    lin_rmse_scores1_mean=lin_rmse_scores1.mean()\n",
    "    print(\"Cross validation mean score for Linear Regression with droppped features: \", lin_rmse_scores1_mean)\n",
    "    lr_confidence1 = lin_reg1.score(housing_t_new, housing_labels_t)\n",
    "    print(\"Confidence score for Linear Regression with dropped features: \", lr_confidence1)\n",
    "    importance_lr1 = lin_reg1.coef_\n",
    "    # summarize feature importance\n",
    "    for i,v in enumerate(importance_lr1):\n",
    "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    # plot feature importance\n",
    "    plt.bar([x for x in range(len(importance_lr1))], importance_lr1)\n",
    "    plt.show()\n",
    "    coef_table1 = pd.DataFrame(list(housing_new.columns)).copy()\n",
    "    coef_table1.columns = ['Features']\n",
    "    coef_table1.insert(len(coef_table1.columns),\"Coefs\",lin_reg1.coef_.transpose())\n",
    "    print(coef_table1)\n",
    "    coef_table_sorted1=coef_table1.sort_values(by='Coefs')\n",
    "    figure()\n",
    "    # Creating a horizontal graph with the values from the pandas Series.\n",
    "    coef_table_sorted1.plot.barh(x='Features', y='Coefs', color=\"green\")\n",
    "    plt.title(\"Feature importance for Linear Regression with dropped features\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
