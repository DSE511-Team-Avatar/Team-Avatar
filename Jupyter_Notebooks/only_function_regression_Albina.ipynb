{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f329ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DSE511. Project 3. Part3. Modeling. Code for Linear Regression, Lasso, Ridge, ElasticNet modeling.Albina Jetybayeva\n",
    "def regression_Albina(housing, housing_labels, housing_t, housing_labels_t):\n",
    "    #Import basic libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import matplotlib as mpl\n",
    "    #%%time\n",
    "    #Model Linear Regression\n",
    "    print(\"Linear Regression\")\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(housing, housing_labels)\n",
    "    #%%time\n",
    "    housing_pred = lin_reg.predict(housing_t)\n",
    "    #Evaluate model\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    lin_mse = mean_squared_error(housing_labels_t, housing_pred)\n",
    "    lin_rmse = np.sqrt(lin_mse)\n",
    "    print(\"RMSE for Linear Regression: \", lin_rmse)\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    lin_mae = mean_absolute_error(housing_labels_t, housing_pred)\n",
    "    print(\"MAE for Linear Regression: \", lin_mae)\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    lin_scores = cross_val_score(lin_reg, housing, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "    lin_rmse_scores_mean=lin_rmse_scores.mean()\n",
    "    print(\"Cross validation mean score for Linear Regression: \", lin_rmse_scores_mean)\n",
    "    lr_confidence = lin_reg.score(housing_t, housing_labels_t)\n",
    "    print(\"Confidence score for Linear Regression: \", lr_confidence)\n",
    "    #Visualize the predicted and actual prices\n",
    "    from sklearn.metrics import r2_score\n",
    "    housing_pred_lr = lin_reg.predict(housing_t)\n",
    "    plt.figure()\n",
    "    plt.errorbar(housing_labels_t, housing_pred_lr, fmt='o', alpha=0.2)\n",
    "    plt.title('Linear regression, R2=%.2f' % r2_score(housing_labels_t, housing_pred_lr))\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    importance = lin_reg.coef_\n",
    "    # summarize feature importance\n",
    "    for i,v in enumerate(importance):\n",
    "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "        # plot feature importance\n",
    "    plt.bar([x for x in range(len(importance))], importance)\n",
    "    plt.show()\n",
    "    #To get the exact names of features create the table\n",
    "    coef_table = pd.DataFrame(list(housing.columns)).copy()\n",
    "    coef_table.columns = ['Features']\n",
    "    coef_table.insert(len(coef_table.columns),\"Coefs\",lin_reg.coef_.transpose())\n",
    "    print(coef_table)\n",
    "    coef_table_sorted=coef_table.sort_values(by='Coefs')\n",
    "    from matplotlib.pyplot import figure\n",
    "    figure()\n",
    "    # Creating a horizontal graph with the values from the pandas Series.\n",
    "    coef_table_sorted.plot.barh(x='Features', y='Coefs', color=\"green\")\n",
    "    plt.title(\"Feature importance for Linear Regression\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.show()\n",
    "    \n",
    "    #To evaluate the performance of the Linear Regression model from the different perspective \n",
    "    #the only important features observed above will be considered in the next part. \n",
    "    #So that \"total_rooms\", \"total_bedrooms\", \"ocean_proximity\", \"population_per_household\" will be dropped.\n",
    "    \n",
    "    #Linear Regression dropped features\n",
    "    print(\"Linear Regression with dropped features\")\n",
    "    housing_new = housing.drop([\"total_rooms\", \"total_bedrooms\", \"ocean_proximity\", \"population_per_household\"], axis=1) # drop labels for training set\n",
    "    housing_t_new = housing_t.drop([\"total_rooms\", \"total_bedrooms\", \"ocean_proximity\", \"population_per_household\"], axis=1) # drop labels for training set\n",
    "    #%%time\n",
    "    lin_reg1 = LinearRegression()\n",
    "    lin_reg1.fit(housing_new, housing_labels)\n",
    "    #%%time\n",
    "    housing_pred1 = lin_reg1.predict(housing_t_new)\n",
    "    #Evaluate Model\n",
    "    lin_mse1 = mean_squared_error(housing_labels_t, housing_pred1)\n",
    "    lin_rmse1 = np.sqrt(lin_mse1)\n",
    "    print(\"RMSE for Linear Regression with dropped features: \", lin_rmse1)\n",
    "    lin_mae1 = mean_absolute_error(housing_labels_t, housing_pred1)\n",
    "    print(\"MAE for Linear Regression with dropped features: \",lin_mae1)\n",
    "    lin_scores1 = cross_val_score(lin_reg1, housing_new, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    lin_rmse_scores1 = np.sqrt(-lin_scores1)\n",
    "    lin_rmse_scores1_mean=lin_rmse_scores1.mean()\n",
    "    print(\"Cross validation mean score for Linear Regression with droppped features: \", lin_rmse_scores1_mean)\n",
    "    lr_confidence1 = lin_reg1.score(housing_t_new, housing_labels_t)\n",
    "    print(\"Confidence score for Linear Regression with dropped features: \", lr_confidence1)\n",
    "    importance_lr1 = lin_reg1.coef_\n",
    "    # summarize feature importance\n",
    "    for i,v in enumerate(importance_lr1):\n",
    "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    # plot feature importance\n",
    "    plt.bar([x for x in range(len(importance_lr1))], importance_lr1)\n",
    "    plt.show()\n",
    "    coef_table1 = pd.DataFrame(list(housing_new.columns)).copy()\n",
    "    coef_table1.columns = ['Features']\n",
    "    coef_table1.insert(len(coef_table1.columns),\"Coefs\",lin_reg1.coef_.transpose())\n",
    "    print(coef_table1)\n",
    "    coef_table_sorted1=coef_table1.sort_values(by='Coefs')\n",
    "    figure()\n",
    "    # Creating a horizontal graph with the values from the pandas Series.\n",
    "    coef_table_sorted1.plot.barh(x='Features', y='Coefs', color=\"green\")\n",
    "    plt.title(\"Feature importance for Linear Regression with dropped features\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.show()\n",
    "    \n",
    "    #Ridge\n",
    "    print(\"Ridge\")\n",
    "    #%%time\n",
    "    from sklearn.linear_model import Ridge\n",
    "    ridge = Ridge(alpha=1)\n",
    "    ridge.fit(housing, housing_labels)\n",
    "    #%%time\n",
    "    housing_pred_r = ridge.predict(housing_t)\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    #Grid Search\n",
    "    clf = Ridge()\n",
    "    grid_values = {'alpha':[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]}\n",
    "    grid_clf_acc = GridSearchCV(clf, param_grid = grid_values, scoring='neg_mean_squared_error',cv=5)\n",
    "    grid_clf_acc.fit(housing, housing_labels)\n",
    "    print(\"Best tuned alpha: \", grid_clf_acc.best_estimator_)\n",
    "    #Predict values based on new parameters\n",
    "    y_pred_acc = grid_clf_acc.predict(housing_t)\n",
    "    #Evaluate model\n",
    "    lin_mse_r = mean_squared_error(housing_labels_t, housing_pred_r)\n",
    "    lin_rmse_r = np.sqrt(lin_mse_r)\n",
    "    print(\"RMSE for Ridge: \", lin_rmse_r)\n",
    "    lin_mse_r1 = mean_squared_error(housing_labels_t, y_pred_acc) #alpha=10\n",
    "    lin_rmse_r1 = np.sqrt(lin_mse_r1)\n",
    "    print(\"RMSE for Ridge - tuned hyperparameter: \", lin_rmse_r1)\n",
    "    lin_mae_r = mean_absolute_error(housing_labels_t, housing_pred_r)\n",
    "    print(\"MAE for Ridge: \", lin_mae_r)\n",
    "    lin_mae_r1 = mean_absolute_error(housing_labels_t, y_pred_acc) #alpha=10\n",
    "    print(\"MAE for Ridge - tuned hyperparameter: \", lin_mae_r1)\n",
    "    lin_scores_r = cross_val_score(ridge, housing, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    lin_rmse_scores_r = np.sqrt(-lin_scores_r)\n",
    "    lin_rmse_scores_r_mean=lin_rmse_scores_r.mean()\n",
    "    print(\"Cross validation mean score for Ridge: \", lin_rmse_scores_r_mean)\n",
    "    lr_confidence_r = ridge.score(housing_t, housing_labels_t)\n",
    "    print(\"Confidence score for Ridge: \", lr_confidence_r)\n",
    "    importance_r1 = ridge.coef_\n",
    "    # summarize feature importance\n",
    "    for i,v in enumerate(importance_r1):\n",
    "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "        # plot feature importance\n",
    "    plt.bar([x for x in range(len(importance_r1))], importance_r1)\n",
    "    plt.show()\n",
    "    coef_table_r = pd.DataFrame(list(housing.columns)).copy()\n",
    "    coef_table_r.columns = ['Features']\n",
    "    coef_table_r.insert(len(coef_table_r.columns),\"Coefs\",ridge.coef_.transpose())\n",
    "    print(coef_table_r)\n",
    "    coef_table_sorted_r=coef_table_r.sort_values(by='Coefs')\n",
    "    figure()\n",
    "    # Creating a horizontal graph with the values from the pandas Series.\n",
    "    coef_table_sorted_r.plot.barh(x='Features', y='Coefs', color=\"green\")\n",
    "    plt.title(\"Feature importance for Ridge\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.show()\n",
    "    \n",
    "    #Lasso\n",
    "    print(\"Lasso\")\n",
    "    #%%time\n",
    "    from sklearn import linear_model\n",
    "    lasso = linear_model.Lasso(alpha=1)\n",
    "    lasso.fit(housing, housing_labels)\n",
    "    #%%time\n",
    "    housing_pred_l = lasso.predict(housing_t)\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    #Grid Search\n",
    "    clf2 = linear_model.Lasso()\n",
    "    grid_values2 = {'alpha':[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]}\n",
    "    grid_clf_acc2 = GridSearchCV(clf2, param_grid = grid_values2, scoring='neg_mean_squared_error',cv=5)\n",
    "    grid_clf_acc2.fit(housing, housing_labels)\n",
    "    print(\"Best tuned alpha: \", grid_clf_acc2.best_estimator_)\n",
    "    #Predict values based on new parameters\n",
    "    y_pred_acc2 = grid_clf_acc2.predict(housing_t)\n",
    "    #Evaluate model\n",
    "    lin_mse_l = mean_squared_error(housing_labels_t, housing_pred_l)\n",
    "    lin_rmse_l = np.sqrt(lin_mse_l)\n",
    "    print(\"RMSE for Lasso: \", lin_rmse_l)\n",
    "    lin_mse_l2 = mean_squared_error(housing_labels_t, y_pred_acc2)\n",
    "    lin_rmse_l2 = np.sqrt(lin_mse_l2)\n",
    "    print(\"RMSE for Lasso - tuned hyperparameter: \", lin_rmse_l2)\n",
    "    lin_mae_l = mean_absolute_error(housing_labels_t, housing_pred_l)\n",
    "    print(\"MAE for Lasso: \", lin_mae_l)\n",
    "    lin_mae_l2 = mean_absolute_error(housing_labels_t, y_pred_acc2)\n",
    "    print(\"MAE for Lasso - tuned hyperparameter: \", lin_mae_l2)\n",
    "    lin_scores_l = cross_val_score(lasso, housing, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    lin_rmse_scores_l = np.sqrt(-lin_scores_l)\n",
    "    lin_rmse_scores_l_mean=lin_rmse_scores_l.mean()\n",
    "    print(\"Cross validation mean score for Lasso: \", lin_rmse_scores_l_mean)\n",
    "    lin_scores_l2 = cross_val_score(grid_clf_acc2, housing, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    lin_rmse_scores_l2 = np.sqrt(-lin_scores_l2)\n",
    "    lin_rmse_scores_l2_mean=lin_rmse_scores_l2.mean()\n",
    "    print(\"Cross validation mean score for Lasso - tuned hyperparameter: \", lin_rmse_scores_l2_mean)\n",
    "    lr_confidence_l = lasso.score(housing_t, housing_labels_t)\n",
    "    print(\"Confidence score for Lasso: \", lr_confidence_l)\n",
    "    lasso2 = linear_model.Lasso(alpha=100)\n",
    "    lasso2.fit(housing, housing_labels)\n",
    "    lr_confidence_l2 = lasso2.score(housing_t, housing_labels_t)\n",
    "    print(\"Confidence score for Lasso - tuned hyperparameter: \", lr_confidence_l2)\n",
    "    importance_las = lasso.coef_\n",
    "    # summarize feature importance\n",
    "    for i,v in enumerate(importance_las):\n",
    "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    # plot feature importance\n",
    "    plt.bar([x for x in range(len(importance_las))], importance_las)\n",
    "    plt.show()\n",
    "    coef_table_l = pd.DataFrame(list(housing.columns)).copy()\n",
    "    coef_table_l.columns = ['Features']\n",
    "    coef_table_l.insert(len(coef_table_l.columns),\"Coefs\",lasso.coef_.transpose())\n",
    "    print(coef_table_l)\n",
    "    coef_table_sorted_l=coef_table_l.sort_values(by='Coefs')\n",
    "    figure()\n",
    "    # Creating a horizontal graph with the values from the pandas Series.\n",
    "    coef_table_sorted_l.plot.barh(x='Features', y='Coefs', color=\"green\")\n",
    "    plt.title(\"Feature importance for Lasso\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.show()\n",
    "    \n",
    "    #ElasticNet\n",
    "    print(\"ElasticNet\")\n",
    "    ##%%time\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    en = ElasticNet(alpha=1) #l1_ratio=0.5\n",
    "    en.fit(housing, housing_labels)\n",
    "    ##%%time\n",
    "    housing_pred_en = en.predict(housing_t)\n",
    "    #Grid Search\n",
    "    clf3 = ElasticNet()\n",
    "    grid_values3 = {'alpha':[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100], 'l1_ratio': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]}\n",
    "    grid_clf_acc3 = GridSearchCV(clf3, param_grid = grid_values3, scoring='neg_mean_squared_error',cv=5)\n",
    "    grid_clf_acc3.fit(housing, housing_labels)\n",
    "    print(\"Best tuned alpha and l1_ratio: \", grid_clf_acc3.best_estimator_)\n",
    "    #Predict values based on new parameters\n",
    "    y_pred_acc3 = grid_clf_acc3.predict(housing_t)\n",
    "    #Evaluating model\n",
    "    lin_mse_en = mean_squared_error(housing_labels_t, housing_pred_en)\n",
    "    lin_rmse_en = np.sqrt(lin_mse_en)\n",
    "    print(\"RMSE for ElasticNet: \", lin_rmse_en) #l1_ratio=0.5, alpha =1\n",
    "    en1 = ElasticNet(alpha=100) #l1_ratio=0.5\n",
    "    en1.fit(housing, housing_labels)\n",
    "    housing_pred_en1 = en1.predict(housing_t)\n",
    "    lin_mse_en1 = mean_squared_error(housing_labels_t, housing_pred_en1)\n",
    "    lin_rmse_en1 = np.sqrt(lin_mse_en1)\n",
    "    print(\"RMSE for ElasticNet - tuned hyperparameter: \", lin_rmse_en1) #l1_ratio=0.5, alpha=100\n",
    "    lin_mae_en = mean_absolute_error(housing_labels_t, housing_pred_en)\n",
    "    print(\"MAE for ElasticNet: \", lin_mae_en)\n",
    "    lin_scores_en = cross_val_score(en, housing, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    lin_rmse_scores_en = np.sqrt(-lin_scores_en)\n",
    "    lin_rmse_scores_en_mean=lin_rmse_scores_en.mean()\n",
    "    print(\"Cross validation mean score for ElasticNet: \", lin_rmse_scores_en_mean)    \n",
    "    lr_confidence_en = en.score(housing_t, housing_labels_t)\n",
    "    print(\"Confidence score for ElasticNet: \", lr_confidence_en)\n",
    "    coef_table_en = pd.DataFrame(list(housing.columns)).copy()\n",
    "    coef_table_en.columns = ['Features']\n",
    "    coef_table_en.insert(len(coef_table_en.columns),\"Coefs\",en.coef_.transpose())\n",
    "    print(coef_table_en)\n",
    "    importance_en = en.coef_\n",
    "    # summarize feature importance\n",
    "    for i,v in enumerate(importance_en):\n",
    "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    # plot feature importance\n",
    "    plt.bar([x for x in range(len(importance_en))], importance_en)\n",
    "    plt.show()\n",
    "    coef_table_sorted_en=coef_table_en.sort_values(by='Coefs')\n",
    "    figure()\n",
    "    # Creating a horizontal graph with the values from the pandas Series.\n",
    "    coef_table_sorted_en.plot.barh(x='Features', y='Coefs', color=\"green\")\n",
    "    plt.title(\"Feature importance for ElasticNet\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808f02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
